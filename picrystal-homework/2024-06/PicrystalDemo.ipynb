{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650ba6e4-6531-46d9-9272-e1c783e4670f",
   "metadata": {},
   "source": [
    "# Picrystal Demo\n",
    "This notebook covers two topics:\n",
    "1. Recent output change \n",
    "2. New Embedders added w.r.t. LLM Assessment\n",
    "\n",
    "## Setting Up the environment\n",
    "\n",
    "Run following commands:\n",
    "\n",
    "git pull git@github.com:QuantPi/picrystal_metric_compute.git\n",
    "<br> cd picrystal_metric_compute  \n",
    "pip install -e ./\n",
    "<br> pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d365e52-72f5-4c60-bd4d-51f41bcd7924",
   "metadata": {},
   "source": [
    "## 1. Recent output change\n",
    "\n",
    "### Brief explanation and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77349f80-2597-4cc4-8f1a-7b8e37261926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from picrystal_metric_compute.embedders import  LabelMapEmbedder\n",
    "from picrystal_metric_compute.core import run_all_metrics\n",
    "from picrystal_metric_compute.metrics_catalog import catalog\n",
    "from picrystal_metric_compute.package_wrappers import PackageWrapper\n",
    "\n",
    "from functools import cached_property\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed84c7d2-dfb8-40b4-84da-67e385620103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiringUseCase:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_csv('https://storage.googleapis.com/picrystal-bucket/hiring/445b7773-3431-4c34-a762-ce8986670aa3_main_hiring_updated.csv')\n",
    "        self.df = self.df.drop(\"Unnamed: 0\", axis=1)\n",
    "    \n",
    "    class_info = [\n",
    "            {'default_class_value': 0, 'value': 0, 'name': 'Hired'},\n",
    "            {'default_class_value': 1, 'value': 1, 'name': 'Not Hired'}\n",
    "    ]\n",
    "    \n",
    "    @cached_property\n",
    "    def model(self):\n",
    "        clf = joblib.load(\"model.joblib\")\n",
    "        return PackageWrapper(model=clf, package_name=\"sklearn\", ml_case=\"classification\")\n",
    "\n",
    "    @cached_property\n",
    "    def inputs(self):\n",
    "\n",
    "        predictors = [\n",
    "            \"State\",\n",
    "            \"Sex\",\n",
    "            \"MaritalDesc\",\n",
    "            \"CitizenDesc\",\n",
    "            \"RaceDesc\",\n",
    "            \"Department\",\n",
    "            \"RecruitmentSource\",\n",
    "            \"PerformanceScore\",\n",
    "            \"SpecialProjectsCount\"\n",
    "        ]\n",
    "\n",
    "        return self.df[predictors].values\n",
    "\n",
    "    @cached_property\n",
    "    def targets(self):\n",
    "\n",
    "        target = \"HiredOrNot\"\n",
    "        return self.df[target].values\n",
    "\n",
    "    embedders = [\n",
    "        LabelMapEmbedder(class_info=class_info, tags=('predictions','binary', 'categorical')),\n",
    "        LabelMapEmbedder(class_info=class_info, on='groundtruth', tags=('groundtruth', 'binary', 'categorical'))    \n",
    "    ]\n",
    "\n",
    "    perturbers = [\n",
    "        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c8838b-91bb-4087-a32c-e1f313922a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase = HiringUseCase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90dc2f8-e0bf-47ab-8bc8-9f81b6caca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {\n",
    "\t\"accuracy\": {\n",
    "\t\t\"function\": \"accuracy\",\n",
    "\t\t\"specification\": {}\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1a9bb6-baaf-4cf2-8fd7-1d64df36d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Metrics specification: {'accuracy': {'function': 'accuracy', 'specification': {}}}\n",
      "INFO:root:Metrics in metrics catalog: ['performance', 'accuracy', 'classification error', 'accuracy regression', 'average distance', 'sklearn_cls_performance_labels', 'sklearn_cls_performance_probabilities', 'sklearn_reg_performance', 'confusion matrix', 'extended binary confusion matrix', 'true negative', 'false positive', 'false negative', 'true positive', 'true negative rate', 'false positive rate', 'false negative rate', 'true positive rate', 'negative predictive value', 'false discovery rate', 'false omission rate', 'positive predictive value', 'positive likelihood ratio', 'negative likelihood ratio', 'diagnostic odds ratio', 'f1 score', 'extended binary confusion matrix accuracy', 'prevalence', 'aggregated extended confusion matrix', 'equalized odds tpr', 'equalized odds fpr', 'equal opportunity', 'predictive parity', 'demographic parity (NYC)', 'performance event bias metric', 'missing values', 'class specific robustness', 'event-based robustness', 'robustness extended binary confusion matrix', 'robustness aggregated extended confusion matrix', 'robustness of fairness accuracy', 'robustness of fairness performance event', 'experimental: perturbation examples', 'experimental: explainability']\n",
      "INFO:root:Collecting metrics\n",
      "INFO:root:Collecting metrics for \"accuracy\"\n",
      "INFO:root:{'function': 'accuracy', 'specification': {}}\n",
      "INFO:root:Searching for suitable parameters for metric accuracy...\n",
      "INFO:root:Found suitable parameters for metric accuracy\n",
      "INFO:root:Parameters: {'dataset': <picrystal_metric_compute.usecase_attributes.AbstractDataset.select_from_usecase.<locals>.Dataset object at 0x7d2f7428ee30>, 'model': <picrystal_metric_compute.usecase_attributes.AbstractModel.select_from_usecase.<locals>.Model object at 0x7d30943a7fa0>, 'targets': <picrystal_metric_compute.embedders.LabelMapEmbedder object at 0x7d2f7428e800>, 'predictions': <picrystal_metric_compute.embedders.LabelMapEmbedder object at 0x7d2f7428cd90>}\n",
      "INFO:root:Executing metrics...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 0/7\n",
      "INFO:root:Executing <picrystal_metric_compute.usecase_attributes.AbstractDataset.select_from_usecase.<locals>.Dataset object at 0x7d2f7428ee30>...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 1/7\n",
      "INFO:root:Executing <picrystal_metric_compute.embedders.LabelMapEmbedder object at 0x7d2f7428e800>...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 2/7\n",
      "INFO:root:Executing <picrystal_metric_compute.usecase_attributes.AbstractModel.select_from_usecase.<locals>.Model object at 0x7d30943a7fa0>...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 3/7\n",
      "INFO:root:Executing <picrystal_metric_compute.embedders.LabelMapEmbedder object at 0x7d2f7428cd90>...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 4/7\n",
      "INFO:root:Executing <function Accuracy.metric at 0x7d2f7425d2d0>...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 5/7\n",
      "INFO:root:Executing <picrystal_metric_compute.metrics_catalog.common.SaveInfo object at 0x7d2f7428df60>...\n",
      "INFO:root:Executing dirrected acyclic graph... Progress 6/7\n",
      "INFO:root:Executing <picrystal_metric_compute.core.ResultSaver object at 0x7d2f7428e830>...\n",
      "INFO:root:Collecting results for \"accuracy\"\n",
      "INFO:root:All tasks are done\n",
      "INFO:root:All metrics finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics': {'accuracy': [{'value': 0.977491961414791,\n",
       "    'name': 'accuracy',\n",
       "    'targets': 'LabelMapEmbedder_2173472566889261758',\n",
       "    'predictions': 'LabelMapEmbedder_2203006555034328968'}]},\n",
       " 'embedders': {'LabelMapEmbedder_2203006555034328968': {'name': 'LabelMapEmbedder embedder on predictions',\n",
       "   'tags': ('inputs',\n",
       "    'categorical',\n",
       "    'provides-groups-info',\n",
       "    'predictions',\n",
       "    'binary',\n",
       "    'categorical'),\n",
       "   'groups': [0, 1]},\n",
       "  'LabelMapEmbedder_2173472566889261758': {'name': 'LabelMapEmbedder embedder on groundtruth',\n",
       "   'tags': ('inputs',\n",
       "    'categorical',\n",
       "    'provides-groups-info',\n",
       "    'groundtruth',\n",
       "    'binary',\n",
       "    'categorical'),\n",
       "   'groups': [0, 1]}},\n",
       " 'perturbers': {},\n",
       " 'picrystal_metric_compute_version': '0.3+0.gba0035e.dirty',\n",
       " 'start_time': '2024-05-10T12:41:11.088451Z',\n",
       " 'end_time': '2024-05-10T12:41:11.118616Z',\n",
       " 'time_elapsed': '-1 day, 23:59:59.969835'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all_metrics(\n",
    "        metric_spec,\n",
    "        usecase,\n",
    "        catalog\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a705101-347d-47b0-ba27-a7f23a86b1a8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2.New Embedders added w.r.t. LLM Assessment\n",
    "\n",
    "### Goal of LLM based Embedders\n",
    "In short to extract information from raw text ==> convert it into arrays (numpy array).\n",
    "And then subsequently picrystal will run tests on this new arrays.\n",
    "\n",
    "And in general if we call an embedder on input (input,target,prediction) it returns numpy array. For example:\n",
    "\n",
    "embedder_obj = SomeEmbedder() \n",
    "<br> embedder_obj( (input,target,prediction) ) ===>> numpy array\n",
    "\n",
    "#### Various embedders covered in this notebook\n",
    "1. LengthTextEmbedder\n",
    "2. VocabularyAppearanceEmbedder\n",
    "3. GenderEmbedder\n",
    "4. EthnicityEmbedder\n",
    "5. RegexMatchEmbedder\n",
    "\n",
    "#### Brief about Tokenizer and field_to_check\n",
    "1. Tokenizer= DefaultEnglishTokenizer(stratification=\"characters\") // \"words\", \"sentences\"\n",
    "2. field_to_check = DefaultSampleToTextProcessor(field_to_check=\"text_field\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8016aa02-6f3c-4d7d-aedc-7f9175c6f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import DefaultEnglishTokenizer, DefaultSampleToTextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90b8e04-2104-4c27-8246-401cab8f2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [\n",
    "    {'problem': 'One plus one', 'answer': '2'},\n",
    "    {'problem': 'What is the sum of 1 and 4?',  'answer': '5'},\n",
    "    {'problem': 'Square root of 105625', 'answer': '325'},\n",
    "    {'problem': 'What is the square root of one hundred five thousand six hundreds twenty five?', 'answer': 'three hundreds twenty five'},\n",
    "    {'problem': 'Denis bought three hundreds apples, and ate zero of them because he doesn\\'t like apples so much, how many apples does he have', 'answer': '300'},\n",
    "    {'problem': '''\n",
    "Antoine analyzed 46.4 LLMs, but then he realized that 5.7 of them were analyzed wrong,\n",
    "10 were not an LLM at all, but two out of 10 has LLM in the name, so they were considered to be an LLM.\n",
    "Also 13 LLM reports were downloded online, but six of them were already analyzed.\n",
    "At the end of the day Antoine found out that he can use triple every LLM because he knows three languages.\n",
    "How many LLMs does he have?\n",
    "''', 'answer': '167.1'},\n",
    "    {'problem': 'Anna had 4 eggs, she cracked one egg, fried one egg and ate one egg. How many eggs does she have at the end', 'answer': '3'},\n",
    "    {'problem': 'Anna had a customer call, there were two attendee in the call, then four attendee disconnected, Anna said \"Great!! now if two more attendee join, then there will be noone in the call\". How many attendee were there?', 'answer': '-2'},\n",
    "    {'problem': '''Denis works 40 hours per week, (5-day work week)\n",
    "Every day he spends 1 hour on staring in the emptiness, 2 hours to eat every snack he finds in the office.\n",
    "Every week he should spend at least 8 hours on discussisng what is a test, and what he should rename more.\n",
    "One day he reserved fully to think about jokes he wants to put into homework.\n",
    "To learn new vim hotkeys he spends 30 minutes on Monday, Wendndsday and Friday and 45 minutes on Tuesday and Thursday.\n",
    "Also he needs to bring all three hundres apples, that he bought for some reason, this takes two and half hour.\n",
    "\n",
    "If Denis would smoke, how many small cigarttes he can afford per week, if smoking one small cigaratte takes 3 minutes?\n",
    "    ''', 'answer': '70'},\n",
    "    {'problem': 'What is the sum  minus one to the power of power of k divided by 2k plus one where k iterates from 0 to infinity', 'answer': 'pi divided by 4'},\n",
    "    {'problem': 'What is square root of 2', 'answer': '1.41421356237...'},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3504d4-40ec-4253-bc7e-2f2f50d2a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = [\n",
    "    'One plus one', \n",
    "    'What is the sum of 1 and 4?', \n",
    "    'Square root of 105625',\n",
    "    'What is the square root of one hundred five thousand six hundreds twenty five?',\n",
    "    'Denis bought three hundreds apples, and ate zero of them because he doesn\\'t like apples so much, how many apples does he have',\n",
    "    '''Antoine analyzed 46.4 LLMs, but then he realized that 5.7 of them were analyzed wrong,\n",
    "10 were not an LLM at all, but two out of 10 has LLM in the name, so they were considered to be an LLM.\n",
    "Also 13 LLM reports were downloded online, but six of them were already analyzed.\n",
    "At the end of the day Antoine found out that he can use triple every LLM because he knows three languages.\n",
    "How many LLMs does he have?''',\n",
    "'Anna had 4 eggs, she cracked one egg, fried one egg and ate one egg. How many eggs does she have at the end',\n",
    "'Anna had a customer call, there were two attendee in the call, then four attendee disconnected, Anna said \"Great!! now if two more attendee join, then there will be noone in the call\". How many attendee were there?',\n",
    "'''Denis works 40 hours per week, (5-day work week)\n",
    "Every day he spends 1 hour on staring in the emptiness, 2 hours to eat every snack he finds in the office.\n",
    "Every week he should spend at least 8 hours on discussisng what is a test, and what he should rename more.\n",
    "One day he reserved fully to think about jokes he wants to put into homework.\n",
    "To learn new vim hotkeys he spends 30 minutes on Monday, Wendndsday and Friday and 45 minutes on Tuesday and Thursday.\n",
    "Also he needs to bring all three hundres apples, that he bought for some reason, this takes two and half hour.\n",
    "\n",
    "If Denis would smoke, how many small cigarttes he can afford per week, if smoking one small cigaratte takes 3 minutes?''',\n",
    "'What is the sum  minus one to the power of power of k divided by 2k plus one where k iterates from 0 to infinity',\n",
    "'What is square root of 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d57f0b-99a1-450c-811b-978ee99c0bc8",
   "metadata": {},
   "source": [
    "## LengthTextEmbedder\n",
    "Usecase: Categorization of input data into bins based on length (characters, word and sentences).\n",
    "<br> The default value of bins and bin length is 10 and 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45e91ca-a1c2-4e09-aa87-a18ea8dadec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import LengthTextEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa51cd77-1c1c-42ae-b942-deaa8a40a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_obj = LengthTextEmbedder(\n",
    "    #n_bins=10,\n",
    "    #bin_width=25,\n",
    "    tokenizer=DefaultEnglishTokenizer(stratification=\"words\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22e41c52-ffa2-4d74-80be-2d5614e780ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 3, 1, 1, 5, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj( (dataset2,None, None) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88e220-7f44-493a-a9b9-314fa8566af1",
   "metadata": {},
   "source": [
    "## VocabularyAppearanceEmbedder\n",
    "Usecase: Searches for \"vocabulary\" in the text.\n",
    "<br> usefull for underlying embedders based on gender, ethinicity and regular expression.\n",
    "\n",
    "There are two (more) required parameters that are necessary:\n",
    "1. vocabulary_in_dict: Is a dictionary of words against group. \n",
    "\n",
    "Like for ('he', 'his', 'him', 'himself') for male and ('she', 'hers', 'her', 'herself') for female.\n",
    "\n",
    "2. groups_processing_rules_dict: How pycrystal uses this information to categorize data.\n",
    "\n",
    "{ 0 : \"male\", 1 : \"female\", 2: \"both\", 3 : \"None\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f002731-a987-4a0b-852c-dc3412357598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import VocabularyAppearanceEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fc9ffd-723b-4d50-ba5b-2468c75fda37",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VocabularyAppearanceEmbedder.__init__() missing 1 required positional argument: 'vocabulary_in_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vemb \u001b[38;5;241m=\u001b[39m \u001b[43mVocabularyAppearanceEmbedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: VocabularyAppearanceEmbedder.__init__() missing 1 required positional argument: 'vocabulary_in_dict'"
     ]
    }
   ],
   "source": [
    "vemb = VocabularyAppearanceEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797f1d9-6b40-4199-bc0d-11a811ccc035",
   "metadata": {},
   "source": [
    "Few things required here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b00bc0-1d57-4102-a89e-1814022bbee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import MentionsCategorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330f3744-0d4e-4cb0-9bf0-4308883fa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_pronouns = ('he', 'his', 'him', 'himself')\n",
    "female_pronouns = ('she', 'hers', 'her', 'herself')\n",
    "\n",
    "vocabulary_in_dict={\n",
    "                'male': MentionsCategorizer(male_pronouns),\n",
    "                'female': MentionsCategorizer(female_pronouns),\n",
    "                'None': MentionsCategorizer(male_pronouns + female_pronouns, include=False)\n",
    "}\n",
    "groups_processing_rules_dict = {\n",
    "                frozenset(['male']): 'Only male',\n",
    "                frozenset(['female']): 'Only female',\n",
    "                frozenset(['male', 'female']): 'Both',\n",
    "                frozenset(['None']): 'None',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "485c798f-15d5-44ea-87cc-46a8ffa791ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_obj = VocabularyAppearanceEmbedder(\n",
    "    vocabulary_in_dict = vocabulary_in_dict,\n",
    "    groups_processing_rules_dict = groups_processing_rules_dict,\n",
    "    tokenizer = DefaultEnglishTokenizer(\"words\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb0aa77d-28b7-4864-a550-815a68262c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., 3., 0., 0., 1., 3., 0., 3., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj((dataset2,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4deb5315-5147-41b9-a108-0f51d64282dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One plus one',\n",
       " 'What is the sum of 1 and 4?',\n",
       " 'Square root of 105625',\n",
       " 'What is the square root of one hundred five thousand six hundreds twenty five?',\n",
       " \"Denis bought three hundreds apples, and ate zero of them because he doesn't like apples so much, how many apples does he have\",\n",
       " 'Antoine analyzed 46.4 LLMs, but then he realized that 5.7 of them were analyzed wrong,\\n10 were not an LLM at all, but two out of 10 has LLM in the name, so they were considered to be an LLM.\\nAlso 13 LLM reports were downloded online, but six of them were already analyzed.\\nAt the end of the day Antoine found out that he can use triple every LLM because he knows three languages.\\nHow many LLMs does he have?',\n",
       " 'Anna had 4 eggs, she cracked one egg, fried one egg and ate one egg. How many eggs does she have at the end',\n",
       " 'Anna had a customer call, there were two attendee in the call, then four attendee disconnected, Anna said \"Great!! now if two more attendee join, then there will be noone in the call\". How many attendee were there?',\n",
       " 'Denis works 40 hours per week, (5-day work week)\\nEvery day he spends 1 hour on staring in the emptiness, 2 hours to eat every snack he finds in the office.\\nEvery week he should spend at least 8 hours on discussisng what is a test, and what he should rename more.\\nOne day he reserved fully to think about jokes he wants to put into homework.\\nTo learn new vim hotkeys he spends 30 minutes on Monday, Wendndsday and Friday and 45 minutes on Tuesday and Thursday.\\nAlso he needs to bring all three hundres apples, that he bought for some reason, this takes two and half hour.\\n\\nIf Denis would smoke, how many small cigarttes he can afford per week, if smoking one small cigaratte takes 3 minutes?',\n",
       " 'What is the sum  minus one to the power of power of k divided by 2k plus one where k iterates from 0 to infinity',\n",
       " 'What is square root of 2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc5a458-b94e-4c18-b3be-3ce428650840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Vocabulary appearance embedder',\n",
       " 'tags': ('inputs',\n",
       "  'categorical',\n",
       "  'provides-groups-info',\n",
       "  'vocabulary-appearance'),\n",
       " 'class_info': [{'value': 0, 'name': 'Only male'},\n",
       "  {'value': 1, 'name': 'Only female'},\n",
       "  {'value': 2, 'name': 'Both'},\n",
       "  {'value': 3, 'name': 'None'}],\n",
       " 'vocabulary_in_dict': {'male': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d17eb0>,\n",
       "  'female': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d9c160>,\n",
       "  'None': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d9f970>},\n",
       " 'groups_processing_rules_dict': {frozenset({'male'}): 'Only male',\n",
       "  frozenset({'female'}): 'Only female',\n",
       "  frozenset({'female', 'male'}): 'Both',\n",
       "  frozenset({'None'}): 'None'},\n",
       " 'sample to text processor config': {'sample to text processor': 'default sample to text processor'},\n",
       " 'tokenizer config': {'stratification': 'words',\n",
       "  'tokenizer used': 'word_tokenize'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6d1fe-8897-4ada-91ce-212d24f7ab2c",
   "metadata": {},
   "source": [
    "##  GenderEmbedder\n",
    "Usecase: categorize input data based on gender information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "219d86cf-770d-4a24-983f-d3b517937c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import GenderEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75d6671b-a57c-4324-a4be-a045c822eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_obj = GenderEmbedder(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5df954a-29a3-423d-ac5f-9f508beec686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Gender embedder',\n",
       " 'tags': ('inputs',\n",
       "  'categorical',\n",
       "  'provides-groups-info',\n",
       "  'vocabulary-appearance'),\n",
       " 'class_info': [{'value': 0, 'name': 'Only male'},\n",
       "  {'value': 1, 'name': 'Only female'},\n",
       "  {'value': 2, 'name': 'Either both or None'}],\n",
       " 'vocabulary_in_dict': {'male': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d30943a77f0>,\n",
       "  'female': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d30943a57b0>,\n",
       "  'None': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d30943a58a0>},\n",
       " 'groups_processing_rules_dict': {frozenset({'male'}): 'Only male',\n",
       "  frozenset({'female'}): 'Only female',\n",
       "  frozenset({'female', 'male'}): 'Either both or None',\n",
       "  frozenset({'None'}): 'Either both or None'},\n",
       " 'sample to text processor config': {'sample to text processor': 'default sample to text processor'},\n",
       " 'tokenizer config': {'stratification': 'words',\n",
       "  'tokenizer used': 'word_tokenize'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a585ae7-7136-4f38-93e3-9854d0e52e29",
   "metadata": {},
   "source": [
    "## EthnicityEmbedder\n",
    "Usecase: To extract ethinicity information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f9fd08-a452-423b-9a02-37a3aaea25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import EthnicityEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ee341a7-123b-41c4-a264-5428d89c45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_obj = EthnicityEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b80665b8-80fa-4618-9571-0d3643207331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Ethnicity embedder',\n",
       " 'tags': ('inputs',\n",
       "  'categorical',\n",
       "  'provides-groups-info',\n",
       "  'vocabulary-appearance'),\n",
       " 'class_info': [{'value': 0, 'name': 'Hispanic or Latino'},\n",
       "  {'value': 1, 'name': 'White'},\n",
       "  {'value': 2, 'name': 'Black or African American'},\n",
       "  {'value': 3, 'name': 'Native Hawaiian or Pacific Islander'},\n",
       "  {'value': 4, 'name': 'Asian'},\n",
       "  {'value': 5, 'name': 'Native American or Alaska Native'},\n",
       "  {'value': 6, 'name': 'None'},\n",
       "  {'value': 7, 'name': 'Two or more'}],\n",
       " 'vocabulary_in_dict': {'Hispanic or Latino': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71e66da0>,\n",
       "  'White': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d16020>,\n",
       "  'Black or African American': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d154b0>,\n",
       "  'Native Hawaiian or Pacific Islander': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d14e50>,\n",
       "  'Asian': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d168c0>,\n",
       "  'Native American or Alaska Native': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d15b70>,\n",
       "  'None': <picrystal_metric_compute.embedders.MentionsCategorizer at 0x7d2f71d17640>},\n",
       " 'groups_processing_rules_dict': <picrystal_metric_compute.embedders.EthnicityEmbedder.__init__.<locals>.CustomGroupProcessor at 0x7d2f71e1bfa0>,\n",
       " 'sample to text processor config': {'sample to text processor': 'default sample to text processor'},\n",
       " 'tokenizer config': {'stratification': 'words',\n",
       "  'tokenizer used': 'word_tokenize'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f85e02a6-f11b-4ce6-9367-af228979890b",
   "metadata": {},
   "source": [
    "'''\n",
    "hispanic_or_latino: Tuple = (\n",
    "    \"mexican\", \"puerto rican\", \"cuban\", \"dominican\", \"central american\",\n",
    "    \"south american\", \"spanish\", \"latin\", \"latino\", \"latinx\", \"hispanic\",\n",
    "    \"chican\", \"spanish-speaking\"\n",
    "),\n",
    "white: Tuple = (\n",
    "    \"german\", \"irish\", \"english\", \"italian\", \"polish\", \"french\", \"scottish\",\n",
    "    \"scandinavian\", \"slavic\", \"caucasian\", \"euro-american\", \"western\", \"white\"\n",
    "),\n",
    "black_or_african_american: Tuple = (\n",
    "    \"african\", \"caribbean\", \"west indian\", \"somali\", \"nigerian\", \"ethiopian\",\n",
    "    \"african american\", \"haitian\", \"black\", \"afro\", \"afro-american\", \"african american\",\n",
    "    \"person of color\",\n",
    "),\n",
    "native_hawaiian_or_pacific_islander: Tuple = (\n",
    "    'hawaii' \"native hawaiian\", \"samoan\", \"guamanian\", \"chamorro\", \"fijian\", \"tongan\",\n",
    "    \"maori\", \"polynesian\", \"micronesian\", \"pacific islander\", \"polynesian\", \"micronesian\",\n",
    "    \"native hawaiian\"\n",
    "),\n",
    "asian: Tuple = (\n",
    "    \"chinese\", \"filipino\", \"asian indian\", \"vietnamese\", \"korean\", \"japanese\", \"thai\", \"indonesian\",\n",
    "    \"burmese\", \"pakistani\", \"asian\", \"east asian\", \"south asian\", \"southeast asian\"\n",
    "),\n",
    "native_america_or_alaska_native: Tuple = (\n",
    "    \"cherokee\", \"navajo\", \"sioux\", \"chippewa\", \"choctaw\", \"lumbee\", \"inupiat\", \"yupik\",\n",
    "    \"aleut\", \"native american\", \"american indian\", \"first nations\", \"indigenous\", \"alaska native\",\n",
    "    \"tribal\",\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0108cd7-c5a5-4e4a-a249-75d3a6baa120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj((dataset2,None,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836764c8-4736-44f2-a289-60d25974a2b7",
   "metadata": {},
   "source": [
    "## RegexMatchEmbedder\n",
    "usecase: match regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "676bc5bb-5595-495f-a952-3a5500f08f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picrystal_metric_compute.embedders import RegexMatchEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f4dc31a-5bd7-4f4b-96f6-077bbc3b7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_obj = RegexMatchEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a0312c-cbb9-4c02-aa5d-2617eee1b67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Regex embedder',\n",
       " 'tags': ('inputs',\n",
       "  'categorical',\n",
       "  'provides-groups-info',\n",
       "  'vocabulary-appearance'),\n",
       " 'class_info': [{'value': 0, 'name': 'credit card'},\n",
       "  {'value': 1, 'name': 'No credit card'}],\n",
       " 'vocabulary_in_dict': {'credit card': <picrystal_metric_compute.embedders.RegexMatchCategorizer at 0x7d2f71eb9e70>,\n",
       "  'No credit card': <picrystal_metric_compute.embedders.RegexMatchCategorizer at 0x7d2f71e18370>},\n",
       " 'groups_processing_rules_dict': {frozenset({'credit card'}): 'credit card',\n",
       "  frozenset({'No credit card'}): 'No credit card'},\n",
       " 'sample to text processor config': {'sample to text processor': 'default sample to text processor'},\n",
       " 'tokenizer config': {'stratification': 'characters', 'tokenizer used': None}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_obj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e946bc3-905c-409d-95ed-4296dd125f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
